{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCaliforniaHousing\u001b[m\u001b[m cal_housing.tgz   spark_book.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "# initialise findspark and provide path to locally installed spark folder\n",
    "# This adds pyspark to sys.path at runtime\n",
    "findspark.init('/usr/local/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Linear Regression Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70904 SparkSubmit\n",
      "70909 Jps\n"
     ]
    }
   ],
   "source": [
    "# Show java virtual machines running\n",
    "!jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "rdd = sc.textFile('CaliforniaHousing/cal_housing.data')\n",
    "\n",
    "# Load in the header\n",
    "header = sc.textFile('CaliforniaHousing/cal_housing.domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude: continuous.',\n",
       " 'latitude: continuous.',\n",
       " 'housingMedianAge: continuous. ',\n",
       " 'totalRooms: continuous. ',\n",
       " 'totalBedrooms: continuous. ',\n",
       " 'population: continuous. ',\n",
       " 'households: continuous. ',\n",
       " 'medianIncome: continuous. ',\n",
       " 'medianHouseValue: continuous. ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The collect() method brings the entire RDD to a single machine\n",
    "header.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-122.230000,37.880000,41.000000,880.000000,129.000000,322.000000,126.000000,8.325200,452600.000000',\n",
       " '-122.220000,37.860000,21.000000,7099.000000,1106.000000,2401.000000,1138.000000,8.301400,358500.000000']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take() is like collect() but safer because it limits the results\n",
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-122.230000',\n",
       "  '37.880000',\n",
       "  '41.000000',\n",
       "  '880.000000',\n",
       "  '129.000000',\n",
       "  '322.000000',\n",
       "  '126.000000',\n",
       "  '8.325200',\n",
       "  '452600.000000'],\n",
       " ['-122.220000',\n",
       "  '37.860000',\n",
       "  '21.000000',\n",
       "  '7099.000000',\n",
       "  '1106.000000',\n",
       "  '2401.000000',\n",
       "  '1138.000000',\n",
       "  '8.301400',\n",
       "  '358500.000000']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split lines on commas\n",
    "rdd = rdd.map(lambda line: line.split(\",\"))\n",
    "\n",
    "# Inspect the first 2 lines \n",
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-124.350000',\n",
       "  '40.540000',\n",
       "  '52.000000',\n",
       "  '1820.000000',\n",
       "  '300.000000',\n",
       "  '806.000000',\n",
       "  '270.000000',\n",
       "  '3.014700',\n",
       "  '94600.000000'],\n",
       " ['-124.300000',\n",
       "  '41.840000',\n",
       "  '17.000000',\n",
       "  '2677.000000',\n",
       "  '531.000000',\n",
       "  '1244.000000',\n",
       "  '456.000000',\n",
       "  '3.031300',\n",
       "  '103600.000000']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take top elements\n",
    "rdd.top(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-122.230000',\n",
       " '37.880000',\n",
       " '41.000000',\n",
       " '880.000000',\n",
       " '129.000000',\n",
       " '322.000000',\n",
       " '126.000000',\n",
       " '8.325200',\n",
       " '452600.000000']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first line \n",
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules \n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Map the RDD to a DF\n",
    "df = rdd.map(lambda line: Row(longitude=line[0], \n",
    "                              latitude=line[1], \n",
    "                              housingMedianAge=line[2],\n",
    "                              totalRooms=line[3],\n",
    "                              totalBedRooms=line[4],\n",
    "                              population=line[5], \n",
    "                              households=line[6],\n",
    "                              medianIncome=line[7],\n",
    "                              medianHouseValue=line[8])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------------+-----------+-------------+-----------+-----------+------------+----------------+\n",
      "|  longitude| latitude|housingMedianAge| totalRooms|totalBedRooms| population| households|medianIncome|medianHouseValue|\n",
      "+-----------+---------+----------------+-----------+-------------+-----------+-----------+------------+----------------+\n",
      "|-122.230000|37.880000|       41.000000| 880.000000|   129.000000| 322.000000| 126.000000|    8.325200|   452600.000000|\n",
      "|-122.220000|37.860000|       21.000000|7099.000000|  1106.000000|2401.000000|1138.000000|    8.301400|   358500.000000|\n",
      "|-122.240000|37.850000|       52.000000|1467.000000|   190.000000| 496.000000| 177.000000|    7.257400|   352100.000000|\n",
      "|-122.250000|37.850000|       52.000000|1274.000000|   235.000000| 558.000000| 219.000000|    5.643100|   341300.000000|\n",
      "|-122.250000|37.850000|       52.000000|1627.000000|   280.000000| 565.000000| 259.000000|    3.846200|   342200.000000|\n",
      "|-122.250000|37.850000|       52.000000| 919.000000|   213.000000| 413.000000| 193.000000|    4.036800|   269700.000000|\n",
      "|-122.250000|37.840000|       52.000000|2535.000000|   489.000000|1094.000000| 514.000000|    3.659100|   299200.000000|\n",
      "|-122.250000|37.840000|       52.000000|3104.000000|   687.000000|1157.000000| 647.000000|    3.120000|   241400.000000|\n",
      "|-122.260000|37.840000|       42.000000|2555.000000|   665.000000|1206.000000| 595.000000|    2.080400|   226700.000000|\n",
      "|-122.250000|37.840000|       52.000000|3549.000000|   707.000000|1551.000000| 714.000000|    3.691200|   261100.000000|\n",
      "|-122.260000|37.850000|       52.000000|2202.000000|   434.000000| 910.000000| 402.000000|    3.203100|   281500.000000|\n",
      "|-122.260000|37.850000|       52.000000|3503.000000|   752.000000|1504.000000| 734.000000|    3.270500|   241800.000000|\n",
      "|-122.260000|37.850000|       52.000000|2491.000000|   474.000000|1098.000000| 468.000000|    3.075000|   213500.000000|\n",
      "|-122.260000|37.840000|       52.000000| 696.000000|   191.000000| 345.000000| 174.000000|    2.673600|   191300.000000|\n",
      "|-122.260000|37.850000|       52.000000|2643.000000|   626.000000|1212.000000| 620.000000|    1.916700|   159200.000000|\n",
      "|-122.260000|37.850000|       50.000000|1120.000000|   283.000000| 697.000000| 264.000000|    2.125000|   140000.000000|\n",
      "|-122.270000|37.850000|       52.000000|1966.000000|   347.000000| 793.000000| 331.000000|    2.775000|   152500.000000|\n",
      "|-122.270000|37.850000|       52.000000|1228.000000|   293.000000| 648.000000| 303.000000|    2.120200|   155500.000000|\n",
      "|-122.260000|37.840000|       50.000000|2239.000000|   455.000000| 990.000000| 419.000000|    1.991100|   158700.000000|\n",
      "|-122.270000|37.840000|       52.000000|1503.000000|   298.000000| 690.000000| 275.000000|    2.603300|   162900.000000|\n",
      "+-----------+---------+----------------+-----------+-------------+-----------+-----------+------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the top 20 rows \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(longitude='-122.230000', latitude='37.880000', housingMedianAge='41.000000', totalRooms='880.000000', totalBedRooms='129.000000', population='322.000000', households='126.000000', medianIncome='8.325200', medianHouseValue='452600.000000')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top row \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housingMedianAge',\n",
       " 'totalRooms',\n",
       " 'totalBedRooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'medianIncome',\n",
       " 'medianHouseValue']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use df.columns to return the columns of your DataFrame.\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('longitude', 'string'),\n",
       " ('latitude', 'string'),\n",
       " ('housingMedianAge', 'string'),\n",
       " ('totalRooms', 'string'),\n",
       " ('totalBedRooms', 'string'),\n",
       " ('population', 'string'),\n",
       " ('households', 'string'),\n",
       " ('medianIncome', 'string'),\n",
       " ('medianHouseValue', 'string')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the data types of all `df` columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- housingMedianAge: string (nullable = true)\n",
      " |-- totalRooms: string (nullable = true)\n",
      " |-- totalBedRooms: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- households: string (nullable = true)\n",
      " |-- medianIncome: string (nullable = true)\n",
      " |-- medianHouseValue: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of `df`\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#declare that each column of the DataFrame df should be cast to a FloatType()\n",
    "df = df.withColumn(\"longitude\", df[\"longitude\"].cast(FloatType())).\\\n",
    "withColumn(\"latitude\", df[\"latitude\"].cast(FloatType())). \\\n",
    "withColumn(\"housingMedianAge\",df[\"housingMedianAge\"].cast(FloatType())). \\\n",
    "withColumn(\"totalRooms\", df[\"totalRooms\"].cast(FloatType())). \\\n",
    "withColumn(\"totalBedRooms\", df[\"totalBedRooms\"].cast(FloatType())). \\\n",
    "withColumn(\"population\", df[\"population\"].cast(FloatType())). \\\n",
    "withColumn(\"households\", df[\"households\"].cast(FloatType())). \\\n",
    "withColumn(\"medianIncome\", df[\"medianIncome\"].cast(FloatType())). \\\n",
    "withColumn(\"medianHouseValue\", df[\"medianHouseValue\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but this approach is better\n",
    "# Import all from `sql.types`\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "  for name in names: \n",
    "     df = df.withColumn(name, df[name].cast(newType))\n",
    "  return df \n",
    "\n",
    "# Assign all column names to `columns`\n",
    "columns = ['households', 'housingMedianAge', 'latitude', 'longitude', 'medianHouseValue', 'medianIncome', 'population', 'totalBedRooms', 'totalRooms']\n",
    "\n",
    "# Conver the `df` columns to `FloatType()`\n",
    "df = convertColumn(df, columns, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- housingMedianAge: float (nullable = true)\n",
      " |-- totalRooms: float (nullable = true)\n",
      " |-- totalBedRooms: float (nullable = true)\n",
      " |-- population: float (nullable = true)\n",
      " |-- households: float (nullable = true)\n",
      " |-- medianIncome: float (nullable = true)\n",
      " |-- medianHouseValue: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|population|totalBedRooms|\n",
      "+----------+-------------+\n",
      "|     322.0|        129.0|\n",
      "|    2401.0|       1106.0|\n",
      "|     496.0|        190.0|\n",
      "|     558.0|        235.0|\n",
      "|     565.0|        280.0|\n",
      "|     413.0|        213.0|\n",
      "|    1094.0|        489.0|\n",
      "|    1157.0|        687.0|\n",
      "|    1206.0|        665.0|\n",
      "|    1551.0|        707.0|\n",
      "+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('population','totalBedRooms').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|housingMedianAge|count|\n",
      "+----------------+-----+\n",
      "|            52.0| 1273|\n",
      "|            51.0|   48|\n",
      "|            50.0|  136|\n",
      "|            49.0|  134|\n",
      "|            48.0|  177|\n",
      "|            47.0|  198|\n",
      "|            46.0|  245|\n",
      "|            45.0|  294|\n",
      "|            44.0|  356|\n",
      "|            43.0|  353|\n",
      "|            42.0|  368|\n",
      "|            41.0|  296|\n",
      "|            40.0|  304|\n",
      "|            39.0|  369|\n",
      "|            38.0|  394|\n",
      "|            37.0|  537|\n",
      "|            36.0|  862|\n",
      "|            35.0|  824|\n",
      "|            34.0|  689|\n",
      "|            33.0|  615|\n",
      "+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"housingMedianAge\").count().sort(\"housingMedianAge\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+\n",
      "|summary|          longitude|         latitude|  housingMedianAge|        totalRooms|    totalBedRooms|        population|       households|      medianIncome|  medianHouseValue|\n",
      "+-------+-------------------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+\n",
      "|  count|              20640|            20640|             20640|             20640|            20640|             20640|            20640|             20640|             20640|\n",
      "|   mean|-119.56970444871473|35.63186143109965|28.639486434108527|2635.7630813953488|537.8980135658915|1425.4767441860465|499.5396802325581|3.8706710030346416|206855.81690891474|\n",
      "| stddev|  2.003531742932898|2.135952380602968| 12.58555761211163|2181.6152515827944| 421.247905943133|  1132.46212176534|382.3297528316098|1.8998217183639696|115395.61587441359|\n",
      "|    min|            -124.35|            32.54|               1.0|               2.0|              1.0|               3.0|              1.0|            0.4999|           14999.0|\n",
      "|    max|            -114.31|            41.95|              52.0|           39320.0|           6445.0|           35682.0|           6082.0|           15.0001|          500001.0|\n",
      "+-------+-------------------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(longitude=-122.2300033569336, latitude=37.880001068115234, housingMedianAge=41.0, totalRooms=880.0, totalBedRooms=129.0, population=322.0, households=126.0, medianIncome=8.325200080871582, medianHouseValue=4.526),\n",
       " Row(longitude=-122.22000122070312, latitude=37.86000061035156, housingMedianAge=21.0, totalRooms=7099.0, totalBedRooms=1106.0, population=2401.0, households=1138.0, medianIncome=8.301400184631348, medianHouseValue=3.585)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import all from `sql.functions` \n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Adjust the values of `medianHouseValue`\n",
    "df = df.withColumn(\"medianHouseValue\", col(\"medianHouseValue\")/100000)\n",
    "\n",
    "# Show the first 2 lines of `df`\n",
    "df.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(longitude=-122.2300033569336, latitude=37.880001068115234, housingMedianAge=41.0, totalRooms=880.0, totalBedRooms=129.0, population=322.0, households=126.0, medianIncome=8.325200080871582, medianHouseValue=4.526, roomsPerHousehold=6.984126984126984, populationPerHousehold=2.5555555555555554, bedroomsPerRoom=0.14659090909090908)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import all from `sql.functions` if you haven't yet\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Divide `totalRooms` by `households`\n",
    "roomsPerHousehold = df.select(col(\"totalRooms\")/col(\"households\"))\n",
    "\n",
    "# Divide `population` by `households`\n",
    "populationPerHousehold = df.select(col(\"population\")/col(\"households\"))\n",
    "\n",
    "# Divide `totalBedRooms` by `totalRooms`\n",
    "bedroomsPerRoom = df.select(col(\"totalBedRooms\")/col(\"totalRooms\"))\n",
    "\n",
    "# Add the new columns to `df`\n",
    "df = df.withColumn(\"roomsPerHousehold\", col(\"totalRooms\")/col(\"households\")) \\\n",
    "   .withColumn(\"populationPerHousehold\", col(\"population\")/col(\"households\")) \\\n",
    "   .withColumn(\"bedroomsPerRoom\", col(\"totalBedRooms\")/col(\"totalRooms\"))\n",
    "   \n",
    "# Inspect the result\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------+-------------------+\n",
      "| roomsPerHousehold|populationPerHousehold|    bedroomsPerRoom|\n",
      "+------------------+----------------------+-------------------+\n",
      "| 6.984126984126984|    2.5555555555555554|0.14659090909090908|\n",
      "| 6.238137082601054|     2.109841827768014|0.15579659106916466|\n",
      "| 8.288135593220339|    2.8022598870056497|0.12951601908657123|\n",
      "|5.8173515981735155|     2.547945205479452|0.18445839874411302|\n",
      "| 6.281853281853282|    2.1814671814671813| 0.1720958819913952|\n",
      "| 4.761658031088083|     2.139896373056995|0.23177366702937977|\n",
      "|4.9319066147859925|    2.1284046692607004|0.19289940828402366|\n",
      "| 4.797527047913447|    1.7882534775888717|0.22132731958762886|\n",
      "| 4.294117647058823|     2.026890756302521| 0.2602739726027397|\n",
      "| 4.970588235294118|     2.172268907563025| 0.1992110453648915|\n",
      "+------------------+----------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"roomsPerHousehold\",\"populationPerHousehold\",\"bedroomsPerRoom\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order and select columns\n",
    "df = df.select(\"medianHouseValue\", \n",
    "              \"totalBedRooms\", \n",
    "              \"population\", \n",
    "              \"households\", \n",
    "              \"medianIncome\", \n",
    "              \"roomsPerHousehold\", \n",
    "              \"populationPerHousehold\", \n",
    "              \"bedroomsPerRoom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+----------+------------+------------------+----------------------+-------------------+\n",
      "|medianHouseValue|totalBedRooms|population|households|medianIncome| roomsPerHousehold|populationPerHousehold|    bedroomsPerRoom|\n",
      "+----------------+-------------+----------+----------+------------+------------------+----------------------+-------------------+\n",
      "|           4.526|        129.0|     322.0|     126.0|      8.3252| 6.984126984126984|    2.5555555555555554|0.14659090909090908|\n",
      "|           3.585|       1106.0|    2401.0|    1138.0|      8.3014| 6.238137082601054|     2.109841827768014|0.15579659106916466|\n",
      "|           3.521|        190.0|     496.0|     177.0|      7.2574| 8.288135593220339|    2.8022598870056497|0.12951601908657123|\n",
      "|           3.413|        235.0|     558.0|     219.0|      5.6431|5.8173515981735155|     2.547945205479452|0.18445839874411302|\n",
      "|           3.422|        280.0|     565.0|     259.0|      3.8462| 6.281853281853282|    2.1814671814671813| 0.1720958819913952|\n",
      "|           2.697|        213.0|     413.0|     193.0|      4.0368| 4.761658031088083|     2.139896373056995|0.23177366702937977|\n",
      "|           2.992|        489.0|    1094.0|     514.0|      3.6591|4.9319066147859925|    2.1284046692607004|0.19289940828402366|\n",
      "|           2.414|        687.0|    1157.0|     647.0|        3.12| 4.797527047913447|    1.7882534775888717|0.22132731958762886|\n",
      "|           2.267|        665.0|    1206.0|     595.0|      2.0804| 4.294117647058823|     2.026890756302521| 0.2602739726027397|\n",
      "|           2.611|        707.0|    1551.0|     714.0|      3.6912| 4.970588235294118|     2.172268907563025| 0.1992110453648915|\n",
      "+----------------+-------------+----------+----------+------------+------------------+----------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `DenseVector`\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "# Define the `input_data` \n",
    "input_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n",
    "\n",
    "# Replace `df` with the new DataFrame\n",
    "df = spark.createDataFrame(input_data, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|4.526|[129.0,322.0,126....|\n",
      "|3.585|[1106.0,2401.0,11...|\n",
      "|3.521|[190.0,496.0,177....|\n",
      "|3.413|[235.0,558.0,219....|\n",
      "|3.422|[280.0,565.0,259....|\n",
      "|2.697|[213.0,413.0,193....|\n",
      "|2.992|[489.0,1094.0,514...|\n",
      "|2.414|[687.0,1157.0,647...|\n",
      "|2.267|[665.0,1206.0,595...|\n",
      "|2.611|[707.0,1551.0,714...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=4.526, features=DenseVector([129.0, 322.0, 126.0, 8.3252, 6.9841, 2.5556, 0.1466]), features_scaled=DenseVector([0.3062, 0.2843, 0.3296, 4.3821, 2.8228, 0.2461, 2.5264])),\n",
       " Row(label=3.585, features=DenseVector([1106.0, 2401.0, 1138.0, 8.3014, 6.2381, 2.1098, 0.1558]), features_scaled=DenseVector([2.6255, 2.1202, 2.9765, 4.3696, 2.5213, 0.2031, 2.6851]))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import `StandardScaler` \n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Initialize the `standardScaler`\n",
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Fit the DataFrame to the scaler\n",
    "scaler = standardScaler.fit(df)\n",
    "\n",
    "# Transform the data in `df` with the scaler\n",
    "scaled_df = scaler.transform(df)\n",
    "\n",
    "# Inspect the result\n",
    "scaled_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            features|     features_scaled|\n",
      "+-----+--------------------+--------------------+\n",
      "|4.526|[129.0,322.0,126....|[0.30623297630686...|\n",
      "|3.585|[1106.0,2401.0,11...|[2.62553233949916...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML model (lin-reg) with MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = scaled_df.randomSplit([.8,.2],seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(df):\n",
    "    print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16525, 3)\n"
     ]
    }
   ],
   "source": [
    "print_shape(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4115, 3)\n"
     ]
    }
   ],
   "source": [
    "print_shape(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `LinearRegression`\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Initialize `lr`\n",
    "lr = LinearRegression(labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the data to the model\n",
    "linearModel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.4542345782162025, 0.14999),\n",
       " (1.6495895629633672, 0.175),\n",
       " (1.482098957606102, 0.332),\n",
       " (1.6123448501897313, 0.346),\n",
       " (1.6541552239238302, 0.35)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predicted = linearModel.transform(test_data)\n",
    "\n",
    "# Extract the predictions and the \"known\" correct labels\n",
    "predictions = predicted.select(\"prediction\").rdd.map(lambda x: x[0])\n",
    "labels = predicted.select(\"label\").rdd.map(lambda x: x[0])\n",
    "\n",
    "# Zip `predictions` and `labels` into a list\n",
    "predictionAndLabel = predictions.zip(labels).collect()\n",
    "\n",
    "# Print out first 5 instances of `predictionAndLabel` \n",
    "predictionAndLabel[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0,0.0,0.0,0.27670678884943006,0.0,0.0,0.0]\n",
      "0.9947076240544817\n"
     ]
    }
   ],
   "source": [
    "# Coefficients for the model\n",
    "print(linearModel.coefficients)\n",
    "\n",
    "# Intercept for the model\n",
    "print(linearModel.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8794333071050418\n",
      "0.4192463677898063\n"
     ]
    }
   ],
   "source": [
    "# Get the RMSE\n",
    "print(linearModel.summary.rootMeanSquaredError)\n",
    "\n",
    "# Get the R2\n",
    "print(linearModel.summary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SparkSession.stop of <pyspark.sql.session.SparkSession object at 0x7fcd5bb1d9a0>>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
